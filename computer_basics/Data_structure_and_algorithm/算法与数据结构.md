# 数据结构与算法

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [数据结构与算法](#数据结构与算法)
  - [一. 基础](#一-基础)
    - [1.1 概念](#11-概念)
    - [1.2 复杂度分析](#12-复杂度分析)
      - [1.2.1 大 O 时间复杂度表示法](#121-大-o-时间复杂度表示法)
      - [1.2.2 时间复杂度分析](#122-时间复杂度分析)
        - [1.2.2.1 几种常见时间复杂度实例分析](#1221-几种常见时间复杂度实例分析)
          - [1.2.2.1.1 O(1) 常量级时间复杂度](#12211-o1-常量级时间复杂度)
          - [1.2.2.1.2 O(logn)、O(nlogn) 对数阶时间复杂度](#12212-ologn-onlogn-对数阶时间复杂度)
          - [1.2.2.1.3 O(m+n)、O(m\*n)](#12213-omn-omn)
      - [1.2.3 空间复杂度分析](#123-空间复杂度分析)
        - [1.2.3.1 最好、最坏情况时间复杂度](#1231-最好-最坏情况时间复杂度)

<!-- /code_chunk_output -->

![数据结构与算法](./image/数据结构与算法.jpg)

基础知识就像是一座大楼的地基，它决定了技术高度。而要想快速做出点事情，前提条件一定是基础能力过硬，“内功”要到位。

## 一. 基础

### 1.1 概念

从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。

数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。

比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。

学习的重点：

1. **复杂度分析方法: 数据结构与算法中最重要的概念，它几乎占了 数据结构和算法 的半壁江山，是数据结构和算法学习的精髓**
   考量效率和资源消耗的方法。
2. 最常用、最基础的 20 个数据结构与算法，学习他们的：“来历”、“特点”、“适合解决什么问题”和“实际的应用场景”。
   - 数据结构 : 数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Tire 树
   - 算法 : 递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

> 学习数据结构和算法的过程，是非常好的思维训练的过程，所以，要多辩证地思考，多问为什么。

**学习技巧**:

1. 边学边练，适度刷题
   用代码实现 学习的数据结构与算法
2. 多问、多思考、多互动
3. 设立一个切实可行的目标
4. 学习知识的过程是反复迭代、不断沉淀的过程。

### 1.2 复杂度分析

数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。

算法代码的执行效率，就要用到 时间、空间复杂度分析。

#### 1.2.1 大 O 时间复杂度表示法

```c
// 求 1,2,3…n 的累加和
int cal(int n) {
  int sum = 0;
  int i = 1;
  for (; i <= n; ++i) {
    sum = sum + i;
  }
  return sum;
}
```

从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：**读数据-运算-写数据**。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 `unit_time`。

在这个假设的基础之上，这段代码的总执行时间是:

第 2、3 行代码分别需要 1 个 `unit_time` 的执行时间，第 4、5 行都运行了 n 遍，所以需要 `2n*unit_time` 的执行时间，所以这段代码总的执行时间就是 `(2n+2)*unit_time`。

```c
int cal(int n) {
  int sum = 0;
  int i = 1;
  int j = 1;
  for (; i <= n; ++i) {
    j = 1;
    for (; j <= n; ++j) {
      sum = sum +  i * j;
    }
  }
}
```

依旧假设每个语句的执行时间是 `unit_time`。那这段代码的总执行时间 T(n) 是:

第 2、3、4 行代码，每行都需要 1 个 `unit_time` 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 `2n * unit_time` 的执行时间，第 7、8 行代码循环执行了 n2 遍，所以需要 `2n2 * unit_time` 的执行时间。
所以，整段代码总的执行时间 **T(n) = (2n^2^+2n+3)\*unit_time**。

通过这两段代码执行时间的推导，可以得到一个非常重要的规律：**所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。**

可以把这个规律总结成一个公式:
![大 O 时间复杂度表示法](./image/大O时间复杂度表示法.png)

其中，`T(n)` 它表示代码执行的时间；`n` 表示数据规模的大小；`f(n)` 表示每行代码执行的次数总和。因为这是一个公式，所以用 `f(n)` 来表示。公式中的 `O`，表示代码的执行时间 `T(n)` 与 `f(n)` 表达式成正比。

所以，第一个例子中的 **T(n) = O(2n+2)**，第二个例子中的 **T(n) = O(2n^2^+2n+3)**。这就是 **大 O 时间复杂度表示法**。
大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示 **代码执行时间随数据规模增长的变化趋势**，所以，也叫作 **渐进时间复杂度**（asymptotic time complexity），简称 **时间复杂度**。

当 n 很大时。而公式中的 低阶、常量、系数 三部分并不左右增长趋势，所以都可以忽略。只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：`T(n) = O(n)`； `T(n) = O(n^2)`。

> 例: 第二段代码中 **T(n) = O(2n^2^+2n+3)** 。在此公式中, 低阶是 2n , 常量是 3 , 系数是 2. 这三部分都不会左右增长趋势,所以可以忽略。

#### 1.2.2 时间复杂度分析

1. **只关注循环执行次数最多的一段代码**
   大 O 这种复杂度表示方法只是表示一种变化趋势。通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。
   所以，**在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了**。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

2. **加法法则：总复杂度等于量级最大的那段代码的复杂度**

   ```c
   int cal(int n) {
     int sum_1 = 0;
     int p = 1;
     for (; p < 100; ++p) {
       sum_1 = sum_1 + p;
     }

     int sum_2 = 0;
     int q = 1;
     for (; q < n; ++q) {
       sum_2 = sum_2 + q;
     }

     int sum_3 = 0;
     int i = 1;
     int j = 1;
     for (; i <= n; ++i) {
       j = 1;
       for (; j <= n; ++j) {
         sum_3 = sum_3 +  i * j;
       }
     }

     return sum_1 + sum_2 + sum_3;
   }
   ```

   这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。
   第一段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。
   第二、三段的时间复杂度为 O(n) 和 O(n^2^)
   综合这三段代码的时间复杂度，取其中最大的量级。所以，整段代码的时间复杂度就为 O(n^2^)。也就是说：**总的时间复杂度就等于量级最大的那段代码的时间复杂度**。那将这个规律抽象成公式就是：

   如果 T1(n)=O(f(n))，T2(n)=O(g(n))，那么 `T(n) = T1(n)+T2(n) = max(O(f(n)), O(g(n))) = O(max(f(n), g(n)))` 。

3. **乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积**
   如果 T1(n)=O(f(n))，T2(n)=O(g(n))，那么 `T(n) = T1(n)*T2(n) = O(f(n))*O(g(n)) = O(f(n)*g(n))`。
   也就是说，假设 T1(n) = O(n)，T2(n) = O(n^2^)，则 **T1(n) \* T2(n) = O(n^3^)**。落实到具体的代码上，可以把乘法法则看成是 **嵌套循环**。

   ```c
   int cal(int n) {
     int ret = 0;
     int i = 1;
     for (; i < n; ++i) {
       ret = ret + f(i);
     }
   }

   int f(int n) {
     int sum = 0;
     int i = 1;
     for (; i < n; ++i) {
       sum = sum + i;
     }
     return sum;
   }
   ```

   单独看 `cal()` 函数。假设 `f()` 只是一个普通的操作，那第 4 ～ 6 行的时间复杂度就是，`T1(n) = O(n)`。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 `T2(n) = O(n)`，所以，整个 `cal()` 函数的时间复杂度就是，**T(n) = T1(n) * T2(n) = O(n*n) = O(n^2^)**。

##### 1.2.2.1 几种常见时间复杂度实例分析

![复杂度量级](./image/复杂度量级.jpg)

以上复杂度量级，可以粗略地分为两类，**多项式量级** 和 **非多项式量级**。其中，非多项式量级只有两个：O(2^n^) 和 O(n!)。

非多项式量级时间复杂度的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题。

> 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。

###### 1.2.2.1.1 O(1) 常量级时间复杂度

O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如下面这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。

```c
int i = 8;
int j = 6;
int sum = i + j;
```

只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度都记作 O(1)。
或者说，**一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是 Ο(1)**。

###### 1.2.2.1.2 O(logn)、O(nlogn) 对数阶时间复杂度

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。

```c
i=1;
while (i <= n)  {
  i = i * 2;
}
```

第三行代码是循环执行次数最多的。所以，只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。实际上，变量 i 的取值就是一个等比数列。如果把它一个一个列出来，应该是这个样子的：

> 2^0^ 2^1^ 2^2^ ··· 2^k^ ··· 2^x^ = n

所以，只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2x=n 求解 x 得到 x=log~2~n，所以，这段代码的时间复杂度就是 **O(log~2~n)**。

对数之间是可以互相转换的，**log~3~n** 就等于 **log~3~2 \* log~2~n**，所以 **O(log~3~n) = O(C \* log~2~n)**。
其中 **C=log~3~2** 是一个常量。基于前面的一个理论：**在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))**。所以，**O(log~2~n)** 就等于 **O(log~3~n)**。
因此，在对数阶时间复杂度的表示方法里，忽略对数的“底”，统一表示为 **O(logn)**。

###### 1.2.2.1.3 O(m+n)、O(m\*n)

代码的复杂度由两个数据的规模来决定

```c
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

从代码中可以看出，m 和 n 是表示两个数据规模。无法事先评估 m 和 n 谁的量级大，所以在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 **O(m+n)**。
针对这种情况，原来的加法法则就不正确了，需要将加法规则改为：**T1(m) + T2(n) = O(f(m) + g(n))**。但是乘法法则继续有效：**T1(m)_T2(n) = O(f(m) _ f(n)) = O(f(m \* n))**。

#### 1.2.3 空间复杂度分析

时间复杂度的全称是**渐进时间复杂度**，表示算法的执行时间与数据规模之间的增长关系。
类比一下，空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**。

```c
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

跟时间复杂度分析一样，可以看到，第 2 行代码中，申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以可以忽略。
第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 **O(n)**。
常见的空间复杂度就是 O(1)、O(n)、O(n^2^)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握刚以上这些内容已经足够了。

##### 1.2.3.1 最好、最坏情况时间复杂度
